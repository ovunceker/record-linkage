{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ecc719",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b22c34d",
   "metadata": {},
   "source": [
    "The data sets we currently have are split into two categories training data and testing data. Right now, each training data set has 700k rows and each testing data set has 300k rows. That means when we are comparing two data sets there are $700000^2$ many pairs to check, which is huge. There are some duplicates in these data sets, i.e. rows with same NPI's. That's why we will drop the duplicates so that there are less pairs to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bbfcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/471968081.py:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataA = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataAtrain.csv\")\n",
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/471968081.py:5: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataB = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataBtrain.csv\")\n",
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/471968081.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataA_test = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataAtest.csv\")\n",
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/471968081.py:9: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataB_test = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataBtest.csv\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "dataA = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataAtrain.csv\")\n",
    "dataB = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataBtrain.csv\")\n",
    "dataC = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataCtrain.csv\")\n",
    "\n",
    "dataA_test = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataAtest.csv\")\n",
    "dataB_test = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataBtest.csv\")\n",
    "dataC_test = pd.read_csv(\"/Users/ovunc/Desktop/Civic_Task/dataCtest.csv\",encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197c65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_prov = dataA.drop_duplicates(subset=[\"NPI\"])\n",
    "dataB_prov = dataB.drop_duplicates(subset=[\"NPI\"])\n",
    "dataC_prov = dataC.drop_duplicates(subset=[\"NPI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38074f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataA_prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad016842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300446"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataB_prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf9dd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588159"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataC_prov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb024b",
   "metadata": {},
   "source": [
    "There are still trillions of pairs to compare. So we will apply blocking methods to reduce the number of pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7def977",
   "metadata": {},
   "source": [
    "## Blocking Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7df7b",
   "metadata": {},
   "source": [
    "From the exploratory data analysis part, we have seen that three columns that doesn't have any missing values are first/last names and state. So what I first wanted to implement is using blocking methods with those three columns. Then I decided to first work with exact blocking. However, when I tried using those three columns, my kernel stopped working because of the abundance of matching. That's why for exact blocking I decided to use ZIP codes with the other two columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553941e",
   "metadata": {},
   "source": [
    "Moreover, while deciding on which blocking method to use we will only focus on the data sets A and B. We will first start by exact blocking using single column: ZIP. Then I will include the initials of first and the last names (The reason for only using initials is because we want to consider typos or different spellings). After each method we will analyze how succesfull that method is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d558f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/3479284249.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"zip5\"] = make_zip5(df[\"ZIP\"])\n",
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/3479284249.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"zip5\"] = make_zip5(df[\"ZIP\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip5</th>\n",
       "      <th>dataA_count</th>\n",
       "      <th>dataB_count</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>77030</td>\n",
       "      <td>1769</td>\n",
       "      <td>1643</td>\n",
       "      <td>2906467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159</th>\n",
       "      <td>44195</td>\n",
       "      <td>1102</td>\n",
       "      <td>574</td>\n",
       "      <td>632548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10162</th>\n",
       "      <td>78229</td>\n",
       "      <td>754</td>\n",
       "      <td>654</td>\n",
       "      <td>493116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>60611</td>\n",
       "      <td>882</td>\n",
       "      <td>519</td>\n",
       "      <td>457758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>63110</td>\n",
       "      <td>916</td>\n",
       "      <td>473</td>\n",
       "      <td>433268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>10016</td>\n",
       "      <td>757</td>\n",
       "      <td>535</td>\n",
       "      <td>404995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7736</th>\n",
       "      <td>55905</td>\n",
       "      <td>1367</td>\n",
       "      <td>290</td>\n",
       "      <td>396430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>19104</td>\n",
       "      <td>846</td>\n",
       "      <td>454</td>\n",
       "      <td>384084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>60612</td>\n",
       "      <td>741</td>\n",
       "      <td>493</td>\n",
       "      <td>365313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>76104</td>\n",
       "      <td>697</td>\n",
       "      <td>509</td>\n",
       "      <td>354773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        zip5  dataA_count  dataB_count  product\n",
       "9911   77030         1769         1643  2906467\n",
       "6159   44195         1102          574   632548\n",
       "10162  78229          754          654   493116\n",
       "8133   60611          882          519   457758\n",
       "8447   63110          916          473   433268\n",
       "1183   10016          757          535   404995\n",
       "7736   55905         1367          290   396430\n",
       "2443   19104          846          454   384084\n",
       "8134   60612          741          493   365313\n",
       "9772   76104          697          509   354773"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exact Blocking\n",
    "# Blocking by using only ZIP code\n",
    "\n",
    "def make_zip5(zip_series):\n",
    "    return (\n",
    "        zip_series\n",
    "        .astype(str)\n",
    "        .str.extract(r\"(\\d{5})\")[0]\n",
    "    )\n",
    "\n",
    "for df in [dataA_prov, dataB_prov]:\n",
    "    df[\"zip5\"] = make_zip5(df[\"ZIP\"])\n",
    "\n",
    "block_sizes = (\n",
    "    dataA_prov.groupby([\"zip5\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"dataA_count\")\n",
    "    .merge(\n",
    "        dataB_prov.groupby([\"zip5\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"dataB_count\"),\n",
    "        on=[\"zip5\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "\n",
    "block_sizes[\"product\"] = (\n",
    "    block_sizes[\"dataA_count\"] * block_sizes[\"dataB_count\"]\n",
    ")\n",
    "\n",
    "block_sizes.sort_values(\"product\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b943068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground truth matches using NPI\n",
    "true_matches = (\n",
    "    dataA_prov[[\"NPI\"]]\n",
    "    .reset_index()\n",
    "    .merge(\n",
    "        dataB_prov[[\"NPI\"]].reset_index(),\n",
    "        on=\"NPI\",\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_A\", \"_B\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set of true match index pairs\n",
    "true_match_pairs = set(\n",
    "    zip(true_matches[\"index_A\"], true_matches[\"index_B\"])\n",
    ")\n",
    "\n",
    "len(true_match_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4636017",
   "metadata": {},
   "source": [
    "Here we see how many NPI's matching there are across data sets A and B. This will be used later checking how successful each blocking method is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb6658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43176018"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocking_cols = [\"zip5\"]\n",
    "\n",
    "dataA_blk = dataA_prov.dropna(subset=blocking_cols).copy()\n",
    "dataB_blk = dataB_prov.dropna(subset=blocking_cols).copy()\n",
    "\n",
    "# Block sizes\n",
    "block_sizes = (\n",
    "    dataA_blk.groupby(blocking_cols)\n",
    "    .size()\n",
    "    .reset_index(name=\"dataA_count\")\n",
    "    .merge(\n",
    "        dataB_blk.groupby(blocking_cols)\n",
    "        .size()\n",
    "        .reset_index(name=\"dataB_count\"),\n",
    "        on=blocking_cols,\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "block_sizes[\"product\"] = (\n",
    "    block_sizes[\"dataA_count\"] * block_sizes[\"dataB_count\"]\n",
    ")\n",
    "\n",
    "# Candidate pairs\n",
    "exact_candidate_pairs = set()\n",
    "\n",
    "groups_A = dataA_blk.groupby(blocking_cols)\n",
    "groups_B = dataB_blk.groupby(blocking_cols)\n",
    "\n",
    "common_keys = set(groups_A.groups) & set(groups_B.groups)\n",
    "\n",
    "for key in common_keys:\n",
    "    idx_A = groups_A.groups[key]\n",
    "    idx_B = groups_B.groups[key]\n",
    "    for i in idx_A:\n",
    "        for j in idx_B:\n",
    "            exact_candidate_pairs.add((i, j))\n",
    "\n",
    "len(exact_candidate_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd0fba",
   "metadata": {},
   "source": [
    "As we can see above there are over 43 million candidates. It is clear that this cannot be used but for the sake of completeness, I will check how successful this one is as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ef9562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8059015156029636"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC_exact_ZIP = (\n",
    "    len(true_match_pairs & exact_candidate_pairs)\n",
    "    / len(true_match_pairs)\n",
    ")\n",
    "\n",
    "PC_exact_ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b74ecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/1996124010.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"last_initial\"] = df[\"Last.Name\"].str[0]\n",
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_92735/1996124010.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"last_initial\"] = df[\"Last.Name\"].str[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_initial</th>\n",
       "      <th>zip5</th>\n",
       "      <th>dataA_count</th>\n",
       "      <th>dataB_count</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66137</th>\n",
       "      <td>S</td>\n",
       "      <td>77030</td>\n",
       "      <td>184</td>\n",
       "      <td>163</td>\n",
       "      <td>29992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47433</th>\n",
       "      <td>M</td>\n",
       "      <td>77030</td>\n",
       "      <td>162</td>\n",
       "      <td>136</td>\n",
       "      <td>22032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>B</td>\n",
       "      <td>77030</td>\n",
       "      <td>113</td>\n",
       "      <td>118</td>\n",
       "      <td>13334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941</th>\n",
       "      <td>C</td>\n",
       "      <td>77030</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>11660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>A</td>\n",
       "      <td>77030</td>\n",
       "      <td>100</td>\n",
       "      <td>114</td>\n",
       "      <td>11400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42112</th>\n",
       "      <td>L</td>\n",
       "      <td>77030</td>\n",
       "      <td>101</td>\n",
       "      <td>86</td>\n",
       "      <td>8686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60676</th>\n",
       "      <td>R</td>\n",
       "      <td>77030</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "      <td>8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64537</th>\n",
       "      <td>S</td>\n",
       "      <td>44195</td>\n",
       "      <td>118</td>\n",
       "      <td>69</td>\n",
       "      <td>8142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26206</th>\n",
       "      <td>G</td>\n",
       "      <td>77030</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>7832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56300</th>\n",
       "      <td>P</td>\n",
       "      <td>77030</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>7568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      last_initial   zip5  dataA_count  dataB_count  product\n",
       "66137            S  77030          184          163    29992\n",
       "47433            M  77030          162          136    22032\n",
       "7971             B  77030          113          118    13334\n",
       "12941            C  77030          106          110    11660\n",
       "2974             A  77030          100          114    11400\n",
       "42112            L  77030          101           86     8686\n",
       "60676            R  77030           85           96     8160\n",
       "64537            S  44195          118           69     8142\n",
       "26206            G  77030           89           88     7832\n",
       "56300            P  77030           86           88     7568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Blocking by ZIP code & initial of last name\n",
    "\n",
    "for df in [dataA_prov, dataB_prov]:\n",
    "    df[\"last_initial\"] = df[\"Last.Name\"].str[0]\n",
    "\n",
    "block_sizes = (\n",
    "    dataA_prov.groupby([\"last_initial\", \"zip5\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"dataA_count\")\n",
    "    .merge(\n",
    "        dataB_prov.groupby([\"last_initial\", \"zip5\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"dataB_count\"),\n",
    "        on=[\"last_initial\", \"zip5\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "\n",
    "block_sizes[\"product\"] = (\n",
    "    block_sizes[\"dataA_count\"] * block_sizes[\"dataB_count\"]\n",
    ")\n",
    "\n",
    "block_sizes.sort_values(\"product\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0486e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2604810"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocking_cols = [\"last_initial\",\"zip5\"]\n",
    "\n",
    "dataA_blk = dataA_prov.dropna(subset=blocking_cols).copy()\n",
    "dataB_blk = dataB_prov.dropna(subset=blocking_cols).copy()\n",
    "\n",
    "# Block sizes\n",
    "block_sizes = (\n",
    "    dataA_blk.groupby(blocking_cols)\n",
    "    .size()\n",
    "    .reset_index(name=\"dataA_count\")\n",
    "    .merge(\n",
    "        dataB_blk.groupby(blocking_cols)\n",
    "        .size()\n",
    "        .reset_index(name=\"dataB_count\"),\n",
    "        on=blocking_cols,\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "block_sizes[\"product\"] = (\n",
    "    block_sizes[\"dataA_count\"] * block_sizes[\"dataB_count\"]\n",
    ")\n",
    "\n",
    "# Candidate pairs\n",
    "exact_candidate_pairs = set()\n",
    "\n",
    "groups_A = dataA_blk.groupby(blocking_cols)\n",
    "groups_B = dataB_blk.groupby(blocking_cols)\n",
    "\n",
    "common_keys = set(groups_A.groups) & set(groups_B.groups)\n",
    "\n",
    "for key in common_keys:\n",
    "    idx_A = groups_A.groups[key]\n",
    "    idx_B = groups_B.groups[key]\n",
    "    for i in idx_A:\n",
    "        for j in idx_B:\n",
    "            exact_candidate_pairs.add((i, j))\n",
    "\n",
    "len(exact_candidate_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12eb54a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961881492958306"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC_exact_ZIP_Linitial = (\n",
    "    len(true_match_pairs & exact_candidate_pairs)\n",
    "    / len(true_match_pairs)\n",
    ")\n",
    "\n",
    "PC_exact_ZIP_Linitial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1d4bc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/zrc90x8538v8_pcdjn16k8ww0000gn/T/ipykernel_44404/3404166453.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"first_initial\"] = df[\"First.Name\"].str[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_initial</th>\n",
       "      <th>last_initial</th>\n",
       "      <th>zip5</th>\n",
       "      <th>dataA_count</th>\n",
       "      <th>dataB_count</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98589</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>77030</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9841</th>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>77030</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89000</th>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>77030</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51494</th>\n",
       "      <td>J</td>\n",
       "      <td>S</td>\n",
       "      <td>77030</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74429</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>77030</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95957</th>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>77030</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71530</th>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>77030</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48247</th>\n",
       "      <td>J</td>\n",
       "      <td>M</td>\n",
       "      <td>77030</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90315</th>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>77030</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96982</th>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>77030</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_initial last_initial   zip5  dataA_count  dataB_count  product\n",
       "98589             S            S  77030           27           21      567\n",
       "9841              A            S  77030           28           18      504\n",
       "89000             R            S  77030           22           20      440\n",
       "51494             J            S  77030           17           21      357\n",
       "74429             M            S  77030           22           15      330\n",
       "95957             S            M  77030           20           14      280\n",
       "71530             M            M  77030           19           14      266\n",
       "48247             J            M  77030           16           15      240\n",
       "90315             S            A  77030           16           14      224\n",
       "96982             S            P  77030           15           14      210"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Blocking by ZIP code & initial of last name & initial of first name\n",
    "\n",
    "for df in [dataA_prov, dataB_prov]:\n",
    "    df[\"first_initial\"] = df[\"First.Name\"].str[0]\n",
    "\n",
    "block_sizes = (\n",
    "    dataA_prov.groupby([\"first_initial\",\"last_initial\", \"zip5\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"dataA_count\")\n",
    "    .merge(\n",
    "        dataB_prov.groupby([\"first_initial\",\"last_initial\", \"zip5\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"dataB_count\"),\n",
    "        on=[\"first_initial\",\"last_initial\", \"zip5\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "\n",
    "block_sizes[\"product\"] = (\n",
    "    block_sizes[\"dataA_count\"] * block_sizes[\"dataB_count\"]\n",
    ")\n",
    "\n",
    "block_sizes.sort_values(\"product\", ascending=False).head(10)\n",
    "\n",
    "# We reduce from trillions -> millions -> hundred thousands -> thousands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffb9f957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256669"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocking_cols = [\"first_initial\", \"last_initial\", \"zip5\"]\n",
    "\n",
    "dataA_blk = dataA_prov.dropna(subset=blocking_cols).copy()\n",
    "dataB_blk = dataB_prov.dropna(subset=blocking_cols).copy()\n",
    "\n",
    "# Block sizes\n",
    "block_sizes = (\n",
    "    dataA_blk.groupby(blocking_cols)\n",
    "    .size()\n",
    "    .reset_index(name=\"dataA_count\")\n",
    "    .merge(\n",
    "        dataB_blk.groupby(blocking_cols)\n",
    "        .size()\n",
    "        .reset_index(name=\"dataB_count\"),\n",
    "        on=blocking_cols,\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "block_sizes[\"product\"] = (\n",
    "    block_sizes[\"dataA_count\"] * block_sizes[\"dataB_count\"]\n",
    ")\n",
    "\n",
    "# Candidate pairs\n",
    "exact_candidate_pairs = set()\n",
    "\n",
    "groups_A = dataA_blk.groupby(blocking_cols)\n",
    "groups_B = dataB_blk.groupby(blocking_cols)\n",
    "\n",
    "common_keys = set(groups_A.groups) & set(groups_B.groups)\n",
    "\n",
    "for key in common_keys:\n",
    "    idx_A = groups_A.groups[key]\n",
    "    idx_B = groups_B.groups[key]\n",
    "    for i in idx_A:\n",
    "        for j in idx_B:\n",
    "            exact_candidate_pairs.add((i, j))\n",
    "\n",
    "len(exact_candidate_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "316d352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955525097828894"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC_exact_ZIP_initials = (\n",
    "    len(true_match_pairs & exact_candidate_pairs)\n",
    "    / len(true_match_pairs)\n",
    ")\n",
    "\n",
    "PC_exact_ZIP_initials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac85d2",
   "metadata": {},
   "source": [
    "As we can see above that we reduced the number of candidate pairs from trillions to hundred thousands but while doing so we lose some precision. We lost almost $21\\%$ of the true pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be441b",
   "metadata": {},
   "source": [
    "Now we will try another method. Specifically, we will try to implement sorted neighborhood method. Now on the sorted neighborhood method we will try using the all three columns we first intended to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6402f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def make_blocking_key(df):\n",
    "    \"\"\"\n",
    "    Create a similarity-preserving blocking key\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df[\"Last.Name\"].str.upper().str.strip().str[:4].fillna(\"\") +\n",
    "        \"_\" +\n",
    "        df[\"First.Name\"].str.upper().str.strip().str[:1].fillna(\"\") +\n",
    "        \"_\" +\n",
    "        df[\"State\"].str.upper().fillna(\"\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94008da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SN_blocking(df_left, df_right, window_size=5):\n",
    "    \"\"\"\n",
    "    Sorted neighborhood blocking across two datasets\n",
    "    Returns list of (left_index, right_index) pairs\n",
    "    \"\"\"\n",
    "    left = df_left.copy()\n",
    "    right = df_right.copy()\n",
    "\n",
    "    left[\"source\"] = \"L\"\n",
    "    right[\"source\"] = \"R\"\n",
    "\n",
    "    left[\"blocking_key\"] = make_blocking_key(left)\n",
    "    right[\"blocking_key\"] = make_blocking_key(right)\n",
    "\n",
    "    combined = pd.concat([left, right], axis=0)\n",
    "    combined = combined.sort_values(\"blocking_key\").reset_index(drop=False)\n",
    "\n",
    "    candidate_pairs = []\n",
    "\n",
    "    for i in range(len(combined)):\n",
    "        window = combined.iloc[i : i + window_size]\n",
    "\n",
    "        left_records = window[window[\"source\"] == \"L\"]\n",
    "        right_records = window[window[\"source\"] == \"R\"]\n",
    "\n",
    "        for l_idx in left_records[\"index\"]:\n",
    "            for r_idx in right_records[\"index\"]:\n",
    "                candidate_pairs.append((l_idx, r_idx))\n",
    "\n",
    "    return candidate_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ffb019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383219"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_candidate_pairs = set(\n",
    "    SN_blocking(dataA_prov, dataB_prov, window_size=2)\n",
    ")\n",
    "\n",
    "len(SNB_candidate_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc8cc82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7750432036231453"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC_SNB = (\n",
    "    len(true_match_pairs & SNB_candidate_pairs)\n",
    "    / len(true_match_pairs)\n",
    ")\n",
    "\n",
    "PC_SNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3336d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1434608"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_candidate_pairs = set(\n",
    "    SN_blocking(dataA_prov, dataB_prov, window_size=5)\n",
    ")\n",
    "\n",
    "len(SNB_candidate_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9e386ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349462685974217"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC_SNB = (\n",
    "    len(true_match_pairs & SNB_candidate_pairs)\n",
    "    / len(true_match_pairs)\n",
    ")\n",
    "\n",
    "PC_SNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2ac12",
   "metadata": {},
   "source": [
    "As we can see that SNB method did work using the State column and it gave us 1.4 million candidate pairs, which is not bad at all. Now we have to see how precise this method compared to exact blocking method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220b697",
   "metadata": {},
   "source": [
    "It is rather obvious that SNB is supreior over the exact blocking. While getting the pairs using this method, we only lost $7\\%$ of the actual pairs. That's why we decided to use this method later in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d94f37bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(389342, 26016),\n",
       " (323512, 109796),\n",
       " (150969, 121193),\n",
       " (381482, 645658),\n",
       " (78114, 610059),\n",
       " (676012, 4807),\n",
       " (515831, 52638),\n",
       " (235685, 295921),\n",
       " (240575, 652994),\n",
       " (107137, 59469),\n",
       " (30881, 340374),\n",
       " (75786, 619949),\n",
       " (17553, 183650),\n",
       " (490569, 115500),\n",
       " (2097, 52712),\n",
       " (587778, 19867),\n",
       " (304149, 326036),\n",
       " (566592, 114318),\n",
       " (107617, 31998),\n",
       " (282017, 120124),\n",
       " (327384, 66091),\n",
       " (156316, 299318),\n",
       " (6525, 486507),\n",
       " (15359, 427236),\n",
       " (134835, 165605),\n",
       " (39923, 467392),\n",
       " (48993, 250546),\n",
       " (166779, 29644),\n",
       " (315608, 45215),\n",
       " (228271, 290574),\n",
       " (182456, 190537),\n",
       " (57896, 446453),\n",
       " (502680, 474061),\n",
       " (612690, 193890),\n",
       " (156423, 423674),\n",
       " (369779, 304022),\n",
       " (592176, 122194),\n",
       " (268221, 482025),\n",
       " (306774, 111252),\n",
       " (591594, 76203),\n",
       " (191034, 593400),\n",
       " (308829, 163993),\n",
       " (315640, 96027),\n",
       " (99895, 107223),\n",
       " (22123, 257572),\n",
       " (151087, 94780),\n",
       " (262365, 8045),\n",
       " (398403, 182077),\n",
       " (399043, 625690),\n",
       " (532916, 173789),\n",
       " (581905, 381084),\n",
       " (33576, 601261),\n",
       " (14882, 364800),\n",
       " (697653, 264738),\n",
       " (488089, 453538),\n",
       " (670369, 446622),\n",
       " (351747, 349240),\n",
       " (362762, 670099),\n",
       " (393057, 407025),\n",
       " (165997, 350980),\n",
       " (509387, 232186),\n",
       " (349799, 188502),\n",
       " (80581, 415384),\n",
       " (20602, 210780),\n",
       " (62807, 696455),\n",
       " (170475, 28127),\n",
       " (413607, 200332),\n",
       " (198635, 593604),\n",
       " (269262, 48844),\n",
       " (46077, 28239),\n",
       " (7963, 536000),\n",
       " (286430, 479621),\n",
       " (106609, 670795),\n",
       " (466242, 216654),\n",
       " (581818, 342592),\n",
       " (476887, 574197),\n",
       " (693015, 333769),\n",
       " (375266, 61885),\n",
       " (406577, 576377),\n",
       " (654312, 373753),\n",
       " (13432, 71885),\n",
       " (505970, 145515),\n",
       " (648990, 94365),\n",
       " (537728, 384939),\n",
       " (668544, 492976),\n",
       " (235673, 336180),\n",
       " (13788, 13611),\n",
       " (278976, 145932),\n",
       " (60348, 13078),\n",
       " (26179, 652110),\n",
       " (387015, 630176),\n",
       " (121778, 598690),\n",
       " (122202, 60895),\n",
       " (74415, 216184),\n",
       " (560365, 216939),\n",
       " (49052, 37916),\n",
       " (586309, 167845),\n",
       " (323768, 489551),\n",
       " (140854, 166605),\n",
       " (514803, 574564),\n",
       " (354375, 84173),\n",
       " (375734, 447455),\n",
       " (206228, 133698),\n",
       " (128307, 163602),\n",
       " (590881, 10615),\n",
       " (632471, 40124),\n",
       " (261254, 150278),\n",
       " (440337, 125328),\n",
       " (230641, 30328),\n",
       " (165071, 630658),\n",
       " (367398, 84102),\n",
       " (38085, 81130),\n",
       " (618349, 329983),\n",
       " (556227, 574892),\n",
       " (123682, 5403),\n",
       " (325463, 58695),\n",
       " (116123, 320381),\n",
       " (676578, 294213),\n",
       " (113068, 607988),\n",
       " (110299, 302024),\n",
       " (282278, 282183),\n",
       " (310115, 483540),\n",
       " (239890, 157824),\n",
       " (417428, 495380),\n",
       " (461611, 155930),\n",
       " (588815, 74253),\n",
       " (473913, 39157),\n",
       " (260504, 503956),\n",
       " (457396, 535005),\n",
       " (194867, 69064),\n",
       " (135920, 666668),\n",
       " (91432, 7699),\n",
       " (10398, 476476),\n",
       " (444717, 248202),\n",
       " (72716, 85870),\n",
       " (58575, 356835),\n",
       " (239666, 25312),\n",
       " (201665, 188731),\n",
       " (617453, 234167),\n",
       " (105574, 548001),\n",
       " (224811, 140745),\n",
       " (683490, 96154),\n",
       " (274055, 17337),\n",
       " (434691, 419755),\n",
       " (113240, 15604),\n",
       " (139377, 451283),\n",
       " (124753, 139426),\n",
       " (351611, 5213),\n",
       " (57921, 128923),\n",
       " (389614, 102166),\n",
       " (488598, 156231),\n",
       " (588355, 29514),\n",
       " (83501, 455851),\n",
       " (274768, 110012),\n",
       " (278087, 6344),\n",
       " (196332, 7225),\n",
       " (148205, 195657),\n",
       " (605242, 278223),\n",
       " (551283, 474044),\n",
       " (46757, 211974),\n",
       " (122514, 80340),\n",
       " (479056, 565269),\n",
       " (7382, 29506),\n",
       " (521890, 155564),\n",
       " (532777, 406251),\n",
       " (150898, 435022),\n",
       " (517676, 433386),\n",
       " (277252, 262809),\n",
       " (222154, 340102),\n",
       " (340728, 200530),\n",
       " (399537, 549474),\n",
       " (333222, 170361),\n",
       " (44265, 207877),\n",
       " (602914, 656683),\n",
       " (535187, 65888),\n",
       " (651420, 183465),\n",
       " (196926, 108287),\n",
       " (51499, 320527),\n",
       " (640946, 423152),\n",
       " (657089, 103816),\n",
       " (579247, 91942),\n",
       " (398472, 320530),\n",
       " (472338, 397609),\n",
       " (111651, 458482),\n",
       " (372786, 88618),\n",
       " (50563, 231378),\n",
       " (453532, 65845),\n",
       " (168111, 538073),\n",
       " (362408, 506833),\n",
       " (383299, 76351),\n",
       " (4876, 375772),\n",
       " (389698, 45597),\n",
       " (95073, 582481),\n",
       " (51560, 689723),\n",
       " (303999, 250037),\n",
       " (173555, 551678),\n",
       " (99832, 255706),\n",
       " (461817, 132346),\n",
       " (498982, 299850),\n",
       " (45424, 398710),\n",
       " (604306, 31730),\n",
       " (355367, 92773),\n",
       " (28828, 683954),\n",
       " (415165, 409774),\n",
       " (51854, 50377),\n",
       " (97645, 138716),\n",
       " (59962, 265261),\n",
       " (129867, 294294),\n",
       " (377003, 699828),\n",
       " (126815, 57470),\n",
       " (455394, 53250),\n",
       " (553732, 207140),\n",
       " (566862, 392172),\n",
       " (375924, 356518),\n",
       " (486168, 76743),\n",
       " (380568, 100911),\n",
       " (499960, 420500),\n",
       " (403374, 59273),\n",
       " (542226, 246663),\n",
       " (423737, 247712),\n",
       " (339210, 140399),\n",
       " (391129, 441013),\n",
       " (234446, 93913),\n",
       " (540421, 281992),\n",
       " (133198, 113324),\n",
       " (329108, 180493),\n",
       " (36249, 66463),\n",
       " (289678, 371419),\n",
       " (353204, 107052),\n",
       " (10248, 43346),\n",
       " (402981, 593348),\n",
       " (161429, 122202),\n",
       " (104427, 64693),\n",
       " (50347, 63240),\n",
       " (5301, 18846),\n",
       " (47188, 144909),\n",
       " (645164, 437373),\n",
       " (345613, 250088),\n",
       " (343274, 588412),\n",
       " (105775, 533441),\n",
       " (550585, 604149),\n",
       " (313628, 41240),\n",
       " (689418, 132098),\n",
       " (3789, 269434),\n",
       " (310121, 108613),\n",
       " (373636, 499341),\n",
       " (166487, 411501),\n",
       " (111564, 347535),\n",
       " (578933, 311437),\n",
       " (499532, 104827),\n",
       " (115306, 335090),\n",
       " (16037, 147887),\n",
       " (256753, 40819),\n",
       " (363937, 196545),\n",
       " (184527, 520030),\n",
       " (479590, 520182),\n",
       " (107750, 68637),\n",
       " (187515, 133133),\n",
       " (262850, 686861),\n",
       " (171265, 419768),\n",
       " (232729, 261061),\n",
       " (187547, 311841),\n",
       " (406597, 19602),\n",
       " (98500, 71040),\n",
       " (6973, 174774),\n",
       " (33705, 301318),\n",
       " (110825, 167221),\n",
       " (94039, 81519),\n",
       " (332704, 19173),\n",
       " (657140, 66681),\n",
       " (150468, 289316),\n",
       " (529693, 72786),\n",
       " (160335, 403235),\n",
       " (114540, 640714),\n",
       " (64274, 506582),\n",
       " (219018, 87953),\n",
       " (255824, 173109),\n",
       " (29779, 478294),\n",
       " (603521, 287453),\n",
       " (607867, 406236),\n",
       " (183098, 179697),\n",
       " (87765, 48589),\n",
       " (402495, 457587),\n",
       " (214560, 215642),\n",
       " (171772, 231488),\n",
       " (61646, 148017),\n",
       " (136715, 373622),\n",
       " (43221, 33611),\n",
       " (219214, 58444),\n",
       " (258503, 417679),\n",
       " (426797, 53177),\n",
       " (70262, 66602),\n",
       " (295114, 49692),\n",
       " (307237, 410172),\n",
       " (276005, 600461),\n",
       " (188455, 172550),\n",
       " (39464, 263764),\n",
       " (83610, 78369),\n",
       " (352960, 14184),\n",
       " (239651, 176064),\n",
       " (31604, 339456),\n",
       " (534487, 246389),\n",
       " (416516, 6545),\n",
       " (86665, 77826),\n",
       " (149304, 318733),\n",
       " (396368, 593674),\n",
       " (67734, 60596),\n",
       " (72841, 89892),\n",
       " (613961, 12668),\n",
       " (501237, 217080),\n",
       " (363677, 537002),\n",
       " (20136, 39216),\n",
       " (178032, 57568),\n",
       " (27524, 228901),\n",
       " (63825, 299804),\n",
       " (376196, 434227),\n",
       " (591506, 18319),\n",
       " (294545, 330570),\n",
       " (245552, 196711),\n",
       " (145187, 207542),\n",
       " (665461, 39224),\n",
       " (584176, 279412),\n",
       " (64221, 25922),\n",
       " (474985, 350129),\n",
       " (74742, 297951),\n",
       " (533813, 68005),\n",
       " (80994, 104946),\n",
       " (680128, 127076),\n",
       " (275850, 446212),\n",
       " (655911, 555514),\n",
       " (217884, 78709),\n",
       " (465295, 9704),\n",
       " (210408, 359979),\n",
       " (378624, 61609),\n",
       " (149870, 6924),\n",
       " (689974, 349890),\n",
       " (324683, 167081),\n",
       " (144341, 248030),\n",
       " (229680, 404270),\n",
       " (470421, 157874),\n",
       " (12790, 299375),\n",
       " (435956, 102633),\n",
       " (59232, 323696),\n",
       " (455262, 24678),\n",
       " (298129, 537460),\n",
       " (411630, 218430),\n",
       " (431291, 598414),\n",
       " (527209, 123186),\n",
       " (458287, 338152),\n",
       " (294153, 101695),\n",
       " (471535, 30948),\n",
       " (652572, 145825),\n",
       " (280884, 645690),\n",
       " (6588, 297058),\n",
       " (47668, 470384),\n",
       " (61837, 619056),\n",
       " (85378, 557636),\n",
       " (354646, 236533),\n",
       " (155208, 536537),\n",
       " (296033, 543162),\n",
       " (306231, 136091),\n",
       " (304166, 101129),\n",
       " (185408, 429765),\n",
       " (567508, 18278),\n",
       " (269377, 148208),\n",
       " (407796, 254267),\n",
       " (79415, 75488),\n",
       " (317063, 382183),\n",
       " (132604, 367032),\n",
       " (561414, 199791),\n",
       " (281649, 34976),\n",
       " (45920, 466970),\n",
       " (316353, 211309),\n",
       " (340716, 212336),\n",
       " (616090, 648665),\n",
       " (230875, 33033),\n",
       " (16657, 342817),\n",
       " (632762, 207816),\n",
       " (42481, 454691),\n",
       " (21313, 117018),\n",
       " (525132, 22175),\n",
       " (339125, 121041),\n",
       " (109160, 232195),\n",
       " (638063, 101922),\n",
       " (559056, 639886),\n",
       " (43495, 597279),\n",
       " (590111, 34001),\n",
       " (574463, 401988),\n",
       " (100945, 137012),\n",
       " (26786, 34047),\n",
       " (125597, 408237),\n",
       " (111715, 27619),\n",
       " (488657, 417942),\n",
       " (614538, 41614),\n",
       " (316083, 534133),\n",
       " (391016, 40083),\n",
       " (216406, 692078),\n",
       " (384514, 621455),\n",
       " (509381, 187428),\n",
       " (353893, 64807),\n",
       " (503475, 439918),\n",
       " (338491, 139720),\n",
       " (646949, 236691),\n",
       " (476283, 324878),\n",
       " (336722, 180341),\n",
       " (289814, 135279),\n",
       " (330941, 401978),\n",
       " (156926, 25074),\n",
       " (132140, 432673),\n",
       " (439617, 104262),\n",
       " (173500, 4689),\n",
       " (414682, 228838),\n",
       " (303177, 417045),\n",
       " (151089, 265246),\n",
       " (508614, 145420),\n",
       " (167212, 459437),\n",
       " (628147, 409025),\n",
       " (644760, 378769),\n",
       " (101139, 31562),\n",
       " (14780, 72442),\n",
       " (551575, 225503),\n",
       " (585875, 215608),\n",
       " (456758, 87307),\n",
       " (687714, 244179),\n",
       " (674145, 416336),\n",
       " (24039, 435662),\n",
       " (303064, 48389),\n",
       " (301561, 184780),\n",
       " (515217, 14119),\n",
       " (306612, 387302),\n",
       " (612534, 163793),\n",
       " (299273, 2474),\n",
       " (34449, 119587),\n",
       " (29748, 244889),\n",
       " (524081, 40700),\n",
       " (6679, 386090),\n",
       " (193876, 375916),\n",
       " (203142, 635446),\n",
       " (38846, 140587),\n",
       " (112911, 474415),\n",
       " (167579, 688766),\n",
       " (2254, 60086),\n",
       " (460235, 169841),\n",
       " (653724, 318416),\n",
       " (31290, 654281),\n",
       " (45362, 551419),\n",
       " (40019, 603130),\n",
       " (575144, 23124),\n",
       " (65470, 237992),\n",
       " (397664, 393232),\n",
       " (56090, 198470),\n",
       " (321892, 137147),\n",
       " (218895, 531312),\n",
       " (217162, 103077),\n",
       " (410874, 34243),\n",
       " (89516, 653703),\n",
       " (293182, 82376),\n",
       " (369995, 562473),\n",
       " (237483, 444446),\n",
       " (126324, 242496),\n",
       " (14935, 101376),\n",
       " (224858, 223894),\n",
       " (44768, 9332),\n",
       " (129662, 101917),\n",
       " (630095, 366029),\n",
       " (190407, 90263),\n",
       " (436986, 360251),\n",
       " (270829, 222966),\n",
       " (34151, 444500),\n",
       " (326244, 7877),\n",
       " (114205, 343111),\n",
       " (244138, 160933),\n",
       " (264315, 359570),\n",
       " (157827, 139222),\n",
       " (454375, 167611),\n",
       " (199316, 476489),\n",
       " (161394, 566831),\n",
       " (258156, 278884),\n",
       " (42435, 328573),\n",
       " (310316, 696876),\n",
       " (685946, 623743),\n",
       " (228170, 25124),\n",
       " (113172, 231398),\n",
       " (384658, 649021),\n",
       " (358404, 5664),\n",
       " (165057, 60101),\n",
       " (632597, 19189),\n",
       " (109409, 239933),\n",
       " (293046, 584185),\n",
       " (262759, 303924),\n",
       " (515506, 97525),\n",
       " (377208, 354701),\n",
       " (436077, 2426),\n",
       " (198954, 129006),\n",
       " (379451, 518016),\n",
       " (686312, 302074),\n",
       " (309990, 149127),\n",
       " (599784, 37395),\n",
       " (46537, 416794),\n",
       " (443670, 45022),\n",
       " (503453, 596377),\n",
       " (316802, 266972),\n",
       " (460125, 597003),\n",
       " (595908, 12283),\n",
       " (200052, 85305),\n",
       " (439776, 207950),\n",
       " (655361, 195341),\n",
       " (142778, 25388),\n",
       " (387588, 72345),\n",
       " (96215, 168980),\n",
       " (112788, 152157),\n",
       " (486101, 101161),\n",
       " (171430, 32633),\n",
       " (404751, 596305),\n",
       " (25932, 3585),\n",
       " (264089, 668706),\n",
       " (414418, 123583),\n",
       " (380264, 213281),\n",
       " (414337, 359569),\n",
       " (519773, 132041),\n",
       " (9122, 58587),\n",
       " (391143, 3858),\n",
       " (339747, 55344),\n",
       " (559584, 27194),\n",
       " (464719, 40982),\n",
       " (577873, 294868),\n",
       " (645195, 422699),\n",
       " (591304, 687887),\n",
       " (288808, 16181),\n",
       " (538623, 294332),\n",
       " (242236, 115896),\n",
       " (11431, 281747),\n",
       " (31683, 215536),\n",
       " (87629, 178903),\n",
       " (483783, 325648),\n",
       " (463031, 156093),\n",
       " (83466, 666035),\n",
       " (401101, 663750),\n",
       " (392676, 54393),\n",
       " (55769, 641226),\n",
       " (663929, 28592),\n",
       " (536434, 384352),\n",
       " (382244, 253955),\n",
       " (394582, 84380),\n",
       " (518116, 45761),\n",
       " (667963, 103689),\n",
       " (662612, 627839),\n",
       " (528176, 518846),\n",
       " (58715, 173351),\n",
       " (568373, 10409),\n",
       " (360864, 566930),\n",
       " (416750, 93409),\n",
       " (30289, 313374),\n",
       " (866, 382096),\n",
       " (122208, 82379),\n",
       " (16460, 103643),\n",
       " (686682, 136692),\n",
       " (458444, 21763),\n",
       " (636066, 245481),\n",
       " (610909, 13159),\n",
       " (446819, 428094),\n",
       " (46553, 586243),\n",
       " (279762, 483867),\n",
       " (501086, 239973),\n",
       " (606515, 18444),\n",
       " (504502, 655335),\n",
       " (45553, 17454),\n",
       " (597307, 75030),\n",
       " (389777, 651053),\n",
       " (273397, 460618),\n",
       " (632140, 142159),\n",
       " (288091, 475203),\n",
       " (18909, 28765),\n",
       " (220067, 255236),\n",
       " (115049, 667170),\n",
       " (370017, 391385),\n",
       " (417788, 279724),\n",
       " (456873, 107257),\n",
       " (690233, 93696),\n",
       " (475364, 619900),\n",
       " (249540, 689833),\n",
       " (627709, 281470),\n",
       " (440267, 13794),\n",
       " (88006, 267791),\n",
       " (492041, 389117),\n",
       " (185044, 281890),\n",
       " (600649, 536240),\n",
       " (126747, 196965),\n",
       " (612746, 57288),\n",
       " (595251, 497346),\n",
       " (387173, 100479),\n",
       " (213551, 538103),\n",
       " (9680, 615972),\n",
       " (7295, 100626),\n",
       " (293616, 92095),\n",
       " (15029, 367536),\n",
       " (522764, 30869),\n",
       " (282408, 402713),\n",
       " (56982, 153575),\n",
       " (649317, 533748),\n",
       " (669788, 342038),\n",
       " (96878, 220681),\n",
       " (9684, 149456),\n",
       " (167642, 50239),\n",
       " (661048, 593727),\n",
       " (269391, 87218),\n",
       " (286487, 585073),\n",
       " (322699, 634027),\n",
       " (363329, 261632),\n",
       " (45750, 117486),\n",
       " (257731, 204397),\n",
       " (302119, 20013),\n",
       " (611623, 13171),\n",
       " (58090, 208283),\n",
       " (297912, 8155),\n",
       " (43635, 287995),\n",
       " (38000, 49989),\n",
       " (224052, 342067),\n",
       " (417125, 322524),\n",
       " (233846, 17358),\n",
       " (33126, 12943),\n",
       " (157355, 246718),\n",
       " (697164, 172147),\n",
       " (10278, 94706),\n",
       " (51602, 111072),\n",
       " (56664, 39871),\n",
       " (619296, 485743),\n",
       " (626291, 504096),\n",
       " (402212, 367019),\n",
       " (635145, 404352),\n",
       " (24185, 303165),\n",
       " (354348, 688241),\n",
       " (448531, 438481),\n",
       " (116607, 59959),\n",
       " (198935, 169493),\n",
       " (424863, 331859),\n",
       " (90540, 159577),\n",
       " (693947, 402429),\n",
       " (420308, 176715),\n",
       " (365908, 185672),\n",
       " (96097, 603315),\n",
       " (294167, 296762),\n",
       " (459236, 120045),\n",
       " (158646, 694556),\n",
       " (288510, 653686),\n",
       " (87328, 360806),\n",
       " (237787, 235597),\n",
       " (312001, 172281),\n",
       " (641140, 404632),\n",
       " (586399, 35334),\n",
       " (28067, 47393),\n",
       " (382083, 18249),\n",
       " (322910, 17411),\n",
       " (378554, 423666),\n",
       " (199505, 122640),\n",
       " (644250, 606378),\n",
       " (124741, 102505),\n",
       " (520510, 307503),\n",
       " (576251, 476053),\n",
       " (129728, 427431),\n",
       " (667701, 80312),\n",
       " (173699, 262192),\n",
       " (179145, 136300),\n",
       " (587915, 176039),\n",
       " (344469, 177768),\n",
       " (451188, 437087),\n",
       " (197898, 59859),\n",
       " (333934, 136531),\n",
       " (142389, 451100),\n",
       " (521299, 128385),\n",
       " (152821, 211941),\n",
       " (154779, 52745),\n",
       " (264546, 493334),\n",
       " (576273, 47084),\n",
       " (110969, 588909),\n",
       " (318527, 381195),\n",
       " (28451, 531710),\n",
       " (472273, 680572),\n",
       " (373837, 21824),\n",
       " (461961, 661072),\n",
       " (335032, 349716),\n",
       " (232375, 243356),\n",
       " (104050, 73176),\n",
       " (487569, 678818),\n",
       " (370793, 450668),\n",
       " (399430, 327080),\n",
       " (44723, 13777),\n",
       " (337660, 268788),\n",
       " (135268, 684424),\n",
       " (344932, 91448),\n",
       " (10687, 109920),\n",
       " (465258, 409592),\n",
       " (259607, 301956),\n",
       " (426867, 28095),\n",
       " (332381, 201478),\n",
       " (189188, 404166),\n",
       " (70743, 376440),\n",
       " (157947, 398176),\n",
       " (191644, 47933),\n",
       " (345889, 201422),\n",
       " (169217, 162745),\n",
       " (472055, 39738),\n",
       " (23454, 545188),\n",
       " (115677, 252346),\n",
       " (174654, 221946),\n",
       " (318907, 102996),\n",
       " (454668, 157741),\n",
       " (581956, 146661),\n",
       " (335221, 39115),\n",
       " (110480, 103562),\n",
       " (276029, 490148),\n",
       " (310549, 513770),\n",
       " (382323, 385070),\n",
       " (261748, 191462),\n",
       " (600412, 31760),\n",
       " (524166, 515558),\n",
       " (272523, 117876),\n",
       " (333491, 127959),\n",
       " (63236, 34415),\n",
       " (503823, 73861),\n",
       " (478795, 246541),\n",
       " (115251, 54062),\n",
       " (264849, 62267),\n",
       " (43039, 694463),\n",
       " (1399, 92567),\n",
       " (362925, 541128),\n",
       " (117075, 195701),\n",
       " (177211, 544777),\n",
       " (142616, 11528),\n",
       " (305409, 151984),\n",
       " (576790, 654295),\n",
       " (189558, 531884),\n",
       " (621836, 23460),\n",
       " (16776, 452367),\n",
       " (79913, 392874),\n",
       " (662635, 429678),\n",
       " (588690, 141995),\n",
       " (314009, 379381),\n",
       " (100868, 442032),\n",
       " (105699, 169282),\n",
       " (194055, 175503),\n",
       " (454114, 143518),\n",
       " (95124, 249345),\n",
       " (413047, 426512),\n",
       " (279530, 554932),\n",
       " (225860, 508300),\n",
       " (102808, 663632),\n",
       " (690502, 305310),\n",
       " (243950, 411358),\n",
       " (261761, 249737),\n",
       " (360640, 653697),\n",
       " (261435, 55471),\n",
       " (671622, 82430),\n",
       " (96984, 679957),\n",
       " (60974, 514168),\n",
       " (268286, 144971),\n",
       " (666145, 93201),\n",
       " (197378, 257570),\n",
       " (300915, 214728),\n",
       " (393297, 268636),\n",
       " (328052, 161040),\n",
       " (281381, 401100),\n",
       " (81708, 691),\n",
       " (308220, 154440),\n",
       " (113608, 24784),\n",
       " (275302, 64578),\n",
       " (462614, 141310),\n",
       " (368346, 16942),\n",
       " (63329, 59788),\n",
       " (439900, 227799),\n",
       " (18470, 218923),\n",
       " (54282, 16534),\n",
       " (423072, 395007),\n",
       " (412548, 134758),\n",
       " (29490, 84795),\n",
       " (502896, 65095),\n",
       " (213768, 91240),\n",
       " (330987, 180767),\n",
       " (85846, 339820),\n",
       " (383092, 66399),\n",
       " (137926, 135810),\n",
       " (275565, 215865),\n",
       " (526648, 458482),\n",
       " (161724, 665729),\n",
       " (361449, 133779),\n",
       " (125858, 311073),\n",
       " (37108, 217033),\n",
       " (24457, 633548),\n",
       " (83211, 270935),\n",
       " (186016, 10508),\n",
       " (110506, 129187),\n",
       " (298714, 653659),\n",
       " (549987, 47609),\n",
       " (9384, 16492),\n",
       " (142545, 236793),\n",
       " (294609, 605864),\n",
       " (302786, 368964),\n",
       " (560448, 227908),\n",
       " (381915, 654672),\n",
       " (227467, 73786),\n",
       " (542490, 99382),\n",
       " (284722, 21595),\n",
       " (654802, 651946),\n",
       " (506545, 537567),\n",
       " (50065, 567135),\n",
       " (374633, 227718),\n",
       " (195410, 439752),\n",
       " (103766, 451973),\n",
       " (3770, 650354),\n",
       " (482902, 34731),\n",
       " (420414, 224414),\n",
       " (88948, 207793),\n",
       " (95476, 185555),\n",
       " (416061, 10529),\n",
       " (657795, 27324),\n",
       " (418286, 267576),\n",
       " (618446, 171637),\n",
       " (289494, 340486),\n",
       " (356773, 624809),\n",
       " (124945, 378608),\n",
       " (408973, 101757),\n",
       " (209539, 386419),\n",
       " (571010, 123423),\n",
       " (450068, 107121),\n",
       " (684552, 207296),\n",
       " (671959, 80563),\n",
       " (122089, 408758),\n",
       " (471779, 275069),\n",
       " (572232, 49048),\n",
       " (306797, 95643),\n",
       " (26959, 59562),\n",
       " (376463, 682630),\n",
       " (2846, 223173),\n",
       " (670517, 240992),\n",
       " (163057, 17110),\n",
       " (408700, 136472),\n",
       " (660698, 64482),\n",
       " (25273, 11764),\n",
       " (181422, 94497),\n",
       " (433894, 241534),\n",
       " (203568, 301970),\n",
       " (437272, 37749),\n",
       " (639167, 365210),\n",
       " (389726, 147838),\n",
       " (257533, 44086),\n",
       " (384199, 226035),\n",
       " (335475, 124838),\n",
       " (225917, 89180),\n",
       " (605329, 44880),\n",
       " (259081, 637031),\n",
       " (530814, 58283),\n",
       " (247471, 494028),\n",
       " (90172, 165089),\n",
       " (418581, 38069),\n",
       " (601602, 42522),\n",
       " (99141, 75683),\n",
       " (478602, 610715),\n",
       " (368767, 465946),\n",
       " (456153, 96340),\n",
       " (358542, 242705),\n",
       " (47698, 275591),\n",
       " (244882, 525461),\n",
       " (419337, 105531),\n",
       " (422124, 60877),\n",
       " (248935, 432368),\n",
       " (119402, 243816),\n",
       " (298090, 58041),\n",
       " (398026, 331909),\n",
       " (474732, 465446),\n",
       " (69063, 522099),\n",
       " (121898, 10367),\n",
       " (337, 20623),\n",
       " (114809, 564652),\n",
       " (441396, 478242),\n",
       " (648404, 341768),\n",
       " (499960, 451645),\n",
       " (12593, 148690),\n",
       " (265111, 108981),\n",
       " (4257, 218037),\n",
       " (437164, 322031),\n",
       " (327510, 162556),\n",
       " (385454, 111368),\n",
       " (692525, 614064),\n",
       " (33203, 95204),\n",
       " (476214, 22990),\n",
       " (451198, 73076),\n",
       " (76647, 209221),\n",
       " (612058, 97183),\n",
       " (600542, 143215),\n",
       " (11444, 524378),\n",
       " (214444, 484897),\n",
       " (293599, 47528),\n",
       " (373943, 169795),\n",
       " (371928, 243221),\n",
       " (391466, 18095),\n",
       " (541594, 153607),\n",
       " (239222, 80066),\n",
       " (695152, 4018),\n",
       " (577292, 50123),\n",
       " (368098, 233538),\n",
       " (4059, 77297),\n",
       " (86351, 103416),\n",
       " (85294, 273105),\n",
       " (256361, 101534),\n",
       " (27090, 509767),\n",
       " (38230, 211288),\n",
       " (641409, 31409),\n",
       " (347070, 316497),\n",
       " (258405, 312904),\n",
       " (173383, 339520),\n",
       " (181978, 244046),\n",
       " (141510, 147852),\n",
       " (88693, 363677),\n",
       " (347698, 182508),\n",
       " (155665, 14665),\n",
       " (534370, 522589),\n",
       " (349337, 67131),\n",
       " (490426, 101910),\n",
       " (182451, 320265),\n",
       " (162043, 315010),\n",
       " (535975, 160888),\n",
       " (438101, 217443),\n",
       " (36941, 130130),\n",
       " (363284, 227475),\n",
       " (611702, 343271),\n",
       " (565170, 250790),\n",
       " (439181, 74718),\n",
       " (698088, 368724),\n",
       " (299694, 50267),\n",
       " (298, 698128),\n",
       " (411143, 218987),\n",
       " (526043, 51805),\n",
       " (139217, 83992),\n",
       " (44715, 471879),\n",
       " (99357, 103684),\n",
       " (436117, 321831),\n",
       " (227030, 470434),\n",
       " (236686, 342331),\n",
       " (487573, 108572),\n",
       " (195829, 501218),\n",
       " (308685, 535337),\n",
       " (235620, 761),\n",
       " (109029, 71553),\n",
       " (364985, 109162),\n",
       " (272695, 667467),\n",
       " (630527, 288024),\n",
       " (326991, 114180),\n",
       " (584722, 146796),\n",
       " (137956, 458685),\n",
       " (570577, 94711),\n",
       " (217435, 502),\n",
       " (349974, 76561),\n",
       " (458035, 97154),\n",
       " (127691, 383539),\n",
       " (248833, 445915),\n",
       " (4516, 18650),\n",
       " (416249, 94501),\n",
       " (8872, 438017),\n",
       " (549024, 376617),\n",
       " (367138, 556241),\n",
       " (599705, 456842),\n",
       " (2950, 16997),\n",
       " (26900, 534478),\n",
       " (14585, 100623),\n",
       " (104426, 58513),\n",
       " (462455, 206595),\n",
       " (182722, 217105),\n",
       " (38573, 596704),\n",
       " (635021, 11666),\n",
       " (128166, 46729),\n",
       " (193706, 206675),\n",
       " (234894, 97543),\n",
       " (390357, 440998),\n",
       " (233315, 163952),\n",
       " (33319, 277261),\n",
       " (9629, 428732),\n",
       " (55955, 31317),\n",
       " (393306, 113745),\n",
       " (425865, 21279),\n",
       " (639262, 273231),\n",
       " (284925, 238224),\n",
       " (164801, 245000),\n",
       " (580896, 198335),\n",
       " (317142, 97726),\n",
       " (102402, 456632),\n",
       " (46685, 570659),\n",
       " (376315, 4256),\n",
       " (306398, 537283),\n",
       " (577304, 22859),\n",
       " (148316, 38335),\n",
       " (152936, 432700),\n",
       " (544720, 596428),\n",
       " (190129, 110704),\n",
       " (9179, 75767),\n",
       " (145985, 83417),\n",
       " (70543, 402742),\n",
       " (389476, 185568),\n",
       " (16126, 160094),\n",
       " (630467, 198118),\n",
       " (330416, 42563),\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a1b58024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184628737.0\n",
      "103774\n",
      "19249\n",
      "NPI                         1184628737\n",
      "Last.Name                        BROWN\n",
      "First.Name                       BARRY\n",
      "Middle.Name                          S\n",
      "Credentials                         DO\n",
      "City                          LOW MOOR\n",
      "State                               VA\n",
      "ZIP                                nan\n",
      "Country                             US\n",
      "Type                 INTERNAL MEDICINE\n",
      "Row.Index                      1775458\n",
      "Street.Address    200 ARH LANE STE 100\n",
      "Name: 103774, dtype: object\n",
      "NPI                                                    1184628737.0\n",
      "First.Name                                                    BARRY\n",
      "Middle.Name                                                     NaN\n",
      "Last.Name                                                     BROWN\n",
      "City                                                       LOW MOOR\n",
      "State                                                            VA\n",
      "ZIP                                                           24457\n",
      "Country                                                          US\n",
      "Row.Index                                                  14904320\n",
      "Street.Address                                 200 ARH LANE STE 100\n",
      "Credentials                                                      MD\n",
      "Type              ALLOPATHIC & OSTEOPATHIC PHYSICIANS|INTERNAL M...\n",
      "Name: 19249, dtype: object\n"
     ]
    }
   ],
   "source": [
    "common_element = next(iter(set(dataA['NPI']) & set(dataB['NPI'])), None)\n",
    "\n",
    "print(common_element)\n",
    "\n",
    "idxA = dataA.index[dataA['NPI'] == common_element][0]\n",
    "idxB = dataB.index[dataB['NPI'] == common_element][0]\n",
    "\n",
    "print(idxA) \n",
    "print(idxB) \n",
    "\n",
    "print(dataA.iloc[103774,:])\n",
    "\n",
    "print(dataB.iloc[19249,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead75ef2",
   "metadata": {},
   "source": [
    "## Intermediate Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686ccdc",
   "metadata": {},
   "source": [
    "Now that we are done with blocking part, we will form the similarity tables. However, before that we will actually a little bit more data cleaning here as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6872deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data set B\n",
    "\n",
    "dataB=dataB.drop(columns=[\"Type\",\"Profile.ID\",\"Name.Suffix\",\"Payment.ID\",\"Payment\",\"Payment.Date\",\"Record.ID\",\n",
    "                          \"Program.Year\",\"Payment.Publication.Date\",\"Postal.Code\",\"Business.Name\",\"Province\"])\n",
    "\n",
    "dataC=dataC.drop(columns=[\"Multiple.NPI\",\"PECOS.ID\",\"Enrollment.ID\",\"Type.Code\",\"Organization.Name\"])\n",
    "\n",
    "dataB_test=dataB_test.drop(columns=[\"Type\",\"Profile.ID\",\"Name.Suffix\",\"Payment.ID\",\"Payment\",\"Payment.Date\",\"Record.ID\",\n",
    "                          \"Program.Year\",\"Payment.Publication.Date\",\"Postal.Code\",\"Business.Name\",\"Province\"])\n",
    "\n",
    "dataC_test=dataC_test.drop(columns=[\"Multiple.NPI\",\"PECOS.ID\",\"Enrollment.ID\",\"Type.Code\",\"Organization.Name\"])\n",
    "\n",
    "dataB = dataB.rename(columns={\"Primary.Type\":\"Credentials\"})\n",
    "dataB = dataB.rename(columns={\"Specialty\":\"Type\"})\n",
    "\n",
    "dataB_test = dataB_test.rename(columns={\"Primary.Type\":\"Credentials\"})\n",
    "dataB_test = dataB_test.rename(columns={\"Specialty\":\"Type\"})\n",
    "\n",
    "dataB['Credentials'] = dataB['Credentials'].str.findall(r'\\b\\w').str.join('').str.upper()\n",
    "dataB['Country'] = dataB['Country'].str.findall(r'\\b\\w').str.join('').str.upper()\n",
    "\n",
    "dataB_test['Credentials'] = dataB_test['Credentials'].str.findall(r'\\b\\w').str.join('').str.upper()\n",
    "dataB_test['Country'] = dataB_test['Country'].str.findall(r'\\b\\w').str.join('').str.upper()\n",
    "\n",
    "dataB = dataB.apply(lambda col: col.str.upper() if col.dtype == 'object' else col)\n",
    "\n",
    "dataB_test = dataB_test.apply(lambda col: col.str.upper() if col.dtype == 'object' else col)\n",
    "\n",
    "dataB[\"ZIP\"] = dataB[\"ZIP\"].map(str)\n",
    "\n",
    "dataB_test[\"ZIP\"] = dataB_test[\"ZIP\"].map(str)\n",
    "\n",
    "dataB['Street.Address'] = dataB['Street.Address'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataB_test['Street.Address'] = dataB_test['Street.Address'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataB['Type'] = dataB['Type'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "\n",
    "dataB_test['Type'] = dataB_test['Type'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebd4938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data set A\n",
    "\n",
    "dataA = dataA.apply(lambda col: col.str.upper() if col.dtype == 'object' else col)\n",
    "\n",
    "dataA_test = dataA_test.apply(lambda col: col.str.upper() if col.dtype == 'object' else col)\n",
    "\n",
    "dataA['Credentials'] = dataA['Credentials'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataA_test['Credentials'] = dataA_test['Credentials'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataA[\"ZIP\"] = dataA[\"ZIP\"].map(str)\n",
    "\n",
    "dataA_test[\"ZIP\"] = dataA_test[\"ZIP\"].map(str)\n",
    "\n",
    "dataA['Street.Address'] = dataA['Street.Address'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataA_test['Street.Address'] = dataA_test['Street.Address'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "dataA['Type'] = dataA['Type'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "\n",
    "dataA_test['Type'] = dataA_test['Type'].str.replace(r'[^\\w\\s]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2da60ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data set C\n",
    "\n",
    "dataC = dataC.apply(lambda col: col.str.upper() if col.dtype == 'object' else col)\n",
    "\n",
    "dataC_test = dataC_test.apply(lambda col: col.str.upper() if col.dtype == 'object' else col)\n",
    "\n",
    "dataC[\"ZIP\"] = dataC[\"ZIP\"].map(str)\n",
    "\n",
    "dataC_test[\"ZIP\"] = dataC_test[\"ZIP\"].map(str)\n",
    "\n",
    "dataC['Type'] = dataC['Type'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "\n",
    "dataC_test['Type'] = dataC_test['Type'].str.replace(r'[^\\w\\s]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506ed9c",
   "metadata": {},
   "source": [
    "## Similarity Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c2bec",
   "metadata": {},
   "source": [
    "Now we will create the similarity tables to use in machine learning. Here for different columns we will use different type of similarity functions/methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f53ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPI_check(i,j):\n",
    "    if dataA[\"NPI\"][i]==dataB[\"NPI\"][j]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1c3454a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance \n",
    "\n",
    "JW = textdistance.JaroWinkler()\n",
    "lev = textdistance.Levenshtein()\n",
    "\n",
    "def safe_jw(a, b):\n",
    "    if not isinstance(a, str) or not isinstance(b, str):\n",
    "        return 0.0\n",
    "    return JW(a, b)\n",
    "\n",
    "\n",
    "def safe_lev(a, b):\n",
    "    if not isinstance(a, str) or not isinstance(b, str):\n",
    "        return 0.0\n",
    "    return lev.normalized_similarity(a, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42a56e",
   "metadata": {},
   "source": [
    "Below what I'm doing is trying to find the most common words that appear on Street.Address column, so that I can drop them. The reason is that since they appear very commonly they will spoil the similarity analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f400e88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ST', 158906),\n",
       " ('STE', 157653),\n",
       " ('AVE', 125621),\n",
       " ('RD', 115973),\n",
       " ('SUITE', 93699),\n",
       " ('DR', 86868),\n",
       " ('BLVD', 59994),\n",
       " ('N', 59233),\n",
       " ('W', 56006),\n",
       " ('E', 54867),\n",
       " ('S', 52403),\n",
       " ('200', 27495),\n",
       " ('100', 27462),\n",
       " ('MEDICAL', 19770),\n",
       " ('PKWY', 17001),\n",
       " ('CENTER', 16870),\n",
       " ('1', 16276),\n",
       " ('300', 15354),\n",
       " ('PARK', 14014),\n",
       " ('101', 13774)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "tokens = (\n",
    "    dataA[\"Street.Address\"]\n",
    "    .str.findall(r\"\\b\\w+\\b\")   \n",
    "    .explode()\n",
    ")\n",
    "\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "token_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "184c404b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('STE', 255484),\n",
       " ('ST', 143939),\n",
       " ('RD', 125187),\n",
       " ('AVE', 122292),\n",
       " ('DR', 92919),\n",
       " ('BLVD', 62382),\n",
       " ('SUITE', 60443),\n",
       " ('N', 59985),\n",
       " ('W', 53699),\n",
       " ('E', 52824),\n",
       " ('S', 50123),\n",
       " ('100', 29752),\n",
       " ('200', 28922),\n",
       " ('PKWY', 21042),\n",
       " ('300', 16024),\n",
       " ('MEDICAL', 15446),\n",
       " ('101', 15129),\n",
       " ('PARK', 14499),\n",
       " ('1', 14027),\n",
       " ('A', 12552)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = (\n",
    "    dataB[\"Street.Address\"]\n",
    "    .str.findall(r\"\\b\\w+\\b\")   \n",
    "    .explode()\n",
    ")\n",
    "\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "token_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9fa94",
   "metadata": {},
   "source": [
    "We see that top 11 words in Street.Address column on both data sets A and B are the same. That's why we will drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db5bea",
   "metadata": {},
   "source": [
    "Below is the function I wrote for street address similarity. It first tokenizes everything from the Street.Address columns and it also calculates the stats of tokens appearing. Then for all the tokens that are rare, we check their similarities using both Jaro-Winkler and Levenshtein. If the words are similar to each other, then we record those words as the same, this is the step of creating canonical map. Then we compare two addresses by using TF-IDF vectorization in cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6801c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_drop = [pair[0] for pair in token_counts.most_common(11)]\n",
    "words_to_drop.extend([\"STREET\", \"BOULEVARD\",\"ROAD\",\"AVENUE\",\"NORTH\",\"WEST\",\"EAST\",\"SOUTH\",\"DRIVE\"])\n",
    "\n",
    "JW_THRESHOLD = 0.85\n",
    "LEV_THRESHOLD = 0.20\n",
    "MAX_RARE_FREQ = 1 \n",
    "\n",
    "def tokenize_address(addr):\n",
    "    if not isinstance(addr, str):\n",
    "        return []\n",
    "\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", addr)\n",
    "    return [t for t in tokens if t not in words_to_drop]\n",
    "\n",
    "def build_token_stats(addresses):\n",
    "    token_lists = [tokenize_address(a) for a in addresses]\n",
    "    flat_tokens = [t for tokens in token_lists for t in tokens]\n",
    "    freq = Counter(flat_tokens)\n",
    "    return token_lists, freq\n",
    "\n",
    "def get_rare_tokens(freq):\n",
    "    return [t for t, c in freq.items() if c <= MAX_RARE_FREQ]\n",
    "\n",
    "def similar_tokens(s1, s2):\n",
    "    if s1.isdigit() or s2.isdigit():\n",
    "        return False\n",
    "\n",
    "    jw = JW(s1, s2)\n",
    "    lev_dist = lev.normalized_distance(s1,s2)\n",
    "\n",
    "    return jw >= JW_THRESHOLD or lev_dist <= LEV_THRESHOLD\n",
    "\n",
    "def build_canonical_map(rare_tokens):\n",
    "    canonical = {}\n",
    "    used = set()\n",
    "\n",
    "    for t1, t2 in combinations(rare_tokens, 2):\n",
    "        if t1 in used or t2 in used:\n",
    "            continue\n",
    "\n",
    "        if similar_tokens(t1, t2):\n",
    "            # choose longer token as canonical (heuristic)\n",
    "            canon = t1 if len(t1) >= len(t2) else t2\n",
    "            other = t2 if canon == t1 else t1\n",
    "\n",
    "            canonical[other] = canon\n",
    "            used.add(other)\n",
    "\n",
    "    return canonical\n",
    "\n",
    "def canonicalize_tokens(token_lists, canon_map):\n",
    "    new_lists = []\n",
    "    for tokens in token_lists:\n",
    "        new_lists.append([canon_map.get(t, t) for t in tokens])\n",
    "    return new_lists\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def compare_two_addresses(addr1, addr2, canon_map):\n",
    "    tokens1 = canonicalize_tokens([tokenize_address(addr1)], canon_map)[0]\n",
    "    tokens2 = canonicalize_tokens([tokenize_address(addr2)], canon_map)[0]\n",
    "\n",
    "    docs = [\" \".join(tokens1), \" \".join(tokens2)]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=str.split,\n",
    "        preprocessor=None,\n",
    "        lowercase=False\n",
    "    )\n",
    "\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "    return cosine_similarity(X)[0, 1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e0b09f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_addresses = list(dataA['Street.Address']) + list(dataB['Street.Address'])\n",
    "\n",
    "token_lists, freq = build_token_stats(all_addresses)\n",
    "rare_tokens = get_rare_tokens(freq)\n",
    "canonical_map = build_canonical_map(rare_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee37029",
   "metadata": {},
   "source": [
    "Next function is for checking the similarity between Type columns. This function primarly checks if two strings contains on word which is \"similar\". And bascially it returns 1 if yes an returns 0 if no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c7c00bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    return re.findall(r\"\\b\\w+\\b\", s)\n",
    "\n",
    "def matching_words(s1, s2, prefix_len=3, jw_threshold=0.85):\n",
    "    tokens1 = tokenize(s1)\n",
    "    tokens2 = tokenize(s2)\n",
    "\n",
    "    # Build prefix  words mapping for s2\n",
    "    prefix_map = {}\n",
    "    for w in tokens2:\n",
    "        if len(w) >= prefix_len:\n",
    "            prefix = w[:prefix_len]\n",
    "            prefix_map.setdefault(prefix, []).append(w)\n",
    "\n",
    "    # Compare tokens from s1\n",
    "    for w1 in tokens1:\n",
    "        if len(w1) < prefix_len:\n",
    "            continue\n",
    "\n",
    "        prefix = w1[:prefix_len]\n",
    "        candidates = prefix_map.get(prefix, [])\n",
    "\n",
    "        for w2 in candidates:\n",
    "            score = JW(w1, w2)\n",
    "            if score >= jw_threshold:\n",
    "                return 1\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "30a50976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for pair in SNB_candidate_pairs:\n",
    "    row = []\n",
    "\n",
    "    row.append(pair)\n",
    "    row.append(NPI_check(pair[0],pair[1]))\n",
    "    row.append(safe_jw(dataA[\"First.Name\"][pair[0]],dataB[\"First.Name\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA[\"Last.Name\"][pair[0]],dataB[\"Last.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA[\"Middle.Name\"][pair[0]],dataB[\"Middle.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA[\"Credentials\"][pair[0]],dataB[\"Credentials\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA[\"City\"][pair[0]],dataB[\"City\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA[\"State\"][pair[0]],dataB[\"State\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA[\"Country\"][pair[0]],dataB[\"Country\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA[\"ZIP\"][pair[0]],dataB[\"ZIP\"][pair[1]]))\n",
    "    row.append(compare_two_addresses(dataA['Street.Address'][pair[0]],dataB['Street.Address'][pair[1]],canonical_map))\n",
    "    row.append(matching_words(dataA['Type'][pair[0]],dataB['Type'][pair[1]]))\n",
    "\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "columns = [\n",
    "    \"pair\",\n",
    "    \"NPI_match\",\n",
    "    \"First.Name\",\n",
    "    \"Last.Name\",\n",
    "    \"Middle.Name\",\n",
    "    \"Credentials\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"ZIP\",\n",
    "    \"Street.Address\",\n",
    "    \"Type\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "23c27b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>NPI_match</th>\n",
       "      <th>First.Name</th>\n",
       "      <th>Last.Name</th>\n",
       "      <th>Middle.Name</th>\n",
       "      <th>Credentials</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Street.Address</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(389342, 26016)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(323512, 109796)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(150969, 121193)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.398810</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(381482, 645658)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(78114, 610059)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.699634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434603</th>\n",
       "      <td>(29114, 176638)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434604</th>\n",
       "      <td>(607598, 654946)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434605</th>\n",
       "      <td>(221280, 112068)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434606</th>\n",
       "      <td>(464048, 224212)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434607</th>\n",
       "      <td>(188303, 78222)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434608 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pair  NPI_match  First.Name  Last.Name  Middle.Name  \\\n",
       "0         (389342, 26016)          0    0.950000   0.847619          0.0   \n",
       "1        (323512, 109796)          1    1.000000   1.000000          1.0   \n",
       "2        (150969, 121193)          0    1.000000   1.000000          0.0   \n",
       "3        (381482, 645658)          0    0.472222   0.634921          0.0   \n",
       "4         (78114, 610059)          0    0.595238   0.699634          0.0   \n",
       "...                   ...        ...         ...        ...          ...   \n",
       "1434603   (29114, 176638)          0    0.537879   0.836111          0.0   \n",
       "1434604  (607598, 654946)          0    0.472222   0.880455          0.0   \n",
       "1434605  (221280, 112068)          0    0.000000   0.790000          0.0   \n",
       "1434606  (464048, 224212)          0    0.539683   0.914286          0.0   \n",
       "1434607   (188303, 78222)          0    0.611111   1.000000          0.0   \n",
       "\n",
       "         Credentials      City  State  Country       ZIP  Street.Address  Type  \n",
       "0           0.000000  0.547619    0.0      1.0  0.600000        0.000000     1  \n",
       "1           1.000000  1.000000    1.0      1.0  0.900000        0.776515     1  \n",
       "2           0.333333  0.398810    0.5      1.0  0.466667        0.000000     0  \n",
       "3           1.000000  0.544444    0.0      1.0  0.600000        0.000000     0  \n",
       "4           0.000000  0.522222    0.0      1.0  0.000000        0.000000     0  \n",
       "...              ...       ...    ...      ...       ...             ...   ...  \n",
       "1434603     1.000000  0.000000    0.0      1.0  0.000000        0.000000     0  \n",
       "1434604     1.000000  0.419192    0.0      1.0  0.622222        0.000000     0  \n",
       "1434605     0.333333  0.555556    0.0      1.0  0.000000        0.000000     0  \n",
       "1434606     0.000000  0.430556    0.0      1.0  0.000000        0.000000     0  \n",
       "1434607     1.000000  0.479798    0.5      1.0  0.466667        0.000000     0  \n",
       "\n",
       "[1434608 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "34c32cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94136"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['NPI_match']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89296bc",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d98268",
   "metadata": {},
   "source": [
    "Before we create the other similarity tables (for A vs C and B vs C), we will first select our model by using cross validation. Later, we will train the model using all three similarity tables. While using cross validation we are actually using stratified k-folds and the reason is that we saw above that there are 94k NPI matches in 1.4m rows. Hence, those 94k matches should be spread somewhat equally to each fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78a951",
   "metadata": {},
   "source": [
    "We will first start by logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "299c52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
    "\n",
    "X = df.drop(columns=[\"pair\", \"NPI_match\"])\n",
    "y = df[\"NPI_match\"]\n",
    "\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"roc_auc\": \"roc_auc\"\n",
    "}\n",
    "\n",
    "results = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "44ac3d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_precision: 0.8974  0.0020\n",
      "test_recall: 0.9945  0.0005\n",
      "test_f1: 0.9434  0.0012\n",
      "test_roc_auc: 0.9997  0.0000\n"
     ]
    }
   ],
   "source": [
    "for metric in [\"test_precision\", \"test_recall\", \"test_f1\", \"test_roc_auc\"]:\n",
    "    mean = np.mean(results[metric])\n",
    "    std = np.std(results[metric])\n",
    "    print(f\"{metric}: {mean:.4f}  {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823c8db",
   "metadata": {},
   "source": [
    "Now we will check random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "540347da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=50,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "metrics_rf = {\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"roc_auc\": []\n",
    "}\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    rf.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = rf.predict(X_val)\n",
    "    y_prob = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    metrics_rf[\"precision\"].append(precision_score(y_val, y_pred))\n",
    "    metrics_rf[\"recall\"].append(recall_score(y_val, y_pred))\n",
    "    metrics_rf[\"f1\"].append(f1_score(y_val, y_pred))\n",
    "    metrics_rf[\"roc_auc\"].append(roc_auc_score(y_val, y_prob))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d5ec9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9275  0.0007\n",
      "recall: 0.9945  0.0003\n",
      "f1: 0.9598  0.0005\n",
      "roc_auc: 0.9998  0.0000\n"
     ]
    }
   ],
   "source": [
    "for m, vals in metrics.items():\n",
    "    print(f\"{m}: {np.mean(vals):.4f}  {np.std(vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bb6a2",
   "metadata": {},
   "source": [
    "Finally, we will check the gradient boosting classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "511245c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "metrics = {\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"roc_auc\": []\n",
    "}\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    gb.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = gb.predict(X_val)\n",
    "    y_prob = gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    metrics[\"precision\"].append(precision_score(y_val, y_pred))\n",
    "    metrics[\"recall\"].append(recall_score(y_val, y_pred))\n",
    "    metrics[\"f1\"].append(f1_score(y_val, y_pred))\n",
    "    metrics[\"roc_auc\"].append(roc_auc_score(y_val, y_prob))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a63bd25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9844  0.0006\n",
      "recall: 0.9718  0.0013\n",
      "f1: 0.9781  0.0008\n",
      "roc_auc: 0.9998  0.0000\n"
     ]
    }
   ],
   "source": [
    "for m, vals in metrics.items():\n",
    "    print(f\"{m}: {np.mean(vals):.4f}  {np.std(vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca9050",
   "metadata": {},
   "source": [
    "Now we will check if gradient boosting is significantly better than the other two models. We will check this using statistical hypothesis testing. Here our null hypothesis is gradient boosting is not much different than the other methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d4060eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94268158, 0.94451587, 0.94238414, 0.94223118, 0.94528845])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_precision = results[\"test_precision\"]\n",
    "lr_recall = results[\"test_recall\"]\n",
    "lr_f1 = results['test_f1']\n",
    "lr_roc_auc = results['test_roc_auc']\n",
    "\n",
    "lr_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d6700490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.959729307118505,\n",
       " 0.9601518026565465,\n",
       " 0.959870848708487,\n",
       " 0.9589525468894128,\n",
       " 0.9603671041837571]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_precision = metrics_rf[\"precision\"]\n",
    "rf_recall = metrics_rf[\"recall\"]\n",
    "rf_f1 = metrics_rf[\"f1\"]\n",
    "rf_roc_auc = metrics_rf['roc_auc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d48152d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9767342354388404,\n",
       " 0.9787484295223075,\n",
       " 0.9789085860743272,\n",
       " 0.9775425088225859,\n",
       " 0.9783718754177249]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_precision = metrics[\"precision\"]\n",
    "gb_recall = metrics[\"recall\"]\n",
    "gb_f1 = metrics[\"f1\"]\n",
    "gb_roc_auc = metrics['roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8cc2506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB vs LR Wilcoxon p-value: 0.03125\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "stat_gb_lr, pval_gb_lr = wilcoxon(\n",
    "    gb_f1,\n",
    "    lr_f1,\n",
    "    alternative=\"greater\"\n",
    ")\n",
    "\n",
    "print(f\"GB vs LR Wilcoxon p-value: {pval_gb_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "06711f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB vs RF Wilcoxon p-value: 0.03125\n"
     ]
    }
   ],
   "source": [
    "stat_gb_rf, pval_gb_rf = wilcoxon(\n",
    "    gb_f1,\n",
    "    rf_f1,\n",
    "    alternative=\"greater\"\n",
    ")\n",
    "\n",
    "print(f\"GB vs RF Wilcoxon p-value: {pval_gb_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c0a0a",
   "metadata": {},
   "source": [
    "By looking at the results, since they are smaller than 0.05, we can statistically say that gradient boosting is significantly better than other two classifiers. That's why we will choose that one while training our model. Now within this model we will check the hyper parameters by using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "0b5e8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"max_depth\": [2, 3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47576cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",            \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9718d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=200; total time= 4.1min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=200; total time= 4.1min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=200; total time= 4.1min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=200; total time= 4.1min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=200; total time= 4.2min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=300; total time= 6.3min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=300; total time= 6.3min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=300; total time= 6.3min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=200; total time= 5.9min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=200; total time= 5.9min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=200; total time= 6.0min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=300; total time= 6.2min\n",
      "[CV] END ..learning_rate=0.03, max_depth=2, n_estimators=300; total time= 6.2min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=200; total time= 5.8min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=200; total time= 5.9min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time= 4.0min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=300; total time= 8.8min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time= 4.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time= 4.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time= 4.0min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=300; total time= 8.7min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=300; total time= 8.7min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=300; total time= 8.8min\n",
      "[CV] END ..learning_rate=0.03, max_depth=3, n_estimators=300; total time= 8.8min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time= 4.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time= 6.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time= 6.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time= 6.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time= 5.8min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time= 6.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time= 5.7min\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time= 6.0min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time= 5.8min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time= 5.5min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time= 5.4min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time= 6.7min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time= 6.6min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time= 6.4min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time= 6.4min\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time= 6.4min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=GradientBoostingClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.03, 0.05], &#x27;max_depth&#x27;: [2, 3],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=GradientBoostingClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.03, 0.05], &#x27;max_depth&#x27;: [2, 3],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: GradientBoostingClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.05, n_estimators=300,\n",
       "                           random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.05, n_estimators=300,\n",
       "                           random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=GradientBoostingClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.03, 0.05], 'max_depth': [2, 3],\n",
       "                         'n_estimators': [200, 300]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"pair\", \"NPI_match\"])\n",
    "y = df[\"NPI_match\"]\n",
    "\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0306d378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 300}"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9baee764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780939715150965"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "03a2ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63dc56e",
   "metadata": {},
   "source": [
    "Now we know which hyper parameters to use while training our model on the whole similarity tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c574767",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf44c25",
   "metadata": {},
   "source": [
    "We will first create the same similarity table for the data sets A and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5f18db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPI_check_AC(i,j):\n",
    "    if dataA[\"NPI\"][i]==dataC[\"NPI\"][j]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "deef9e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1824236"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_candidate_pairs_AC = set(\n",
    "    SN_blocking(dataA_prov, dataC_prov, window_size=5)\n",
    ")\n",
    "\n",
    "len(SNB_candidate_pairs_AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e533b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pair in SNB_candidate_pairs_AC:\n",
    "    row = []\n",
    "\n",
    "    row.append(pair)\n",
    "    row.append(NPI_check_AC(pair[0],pair[1]))\n",
    "    row.append(safe_jw(dataA[\"First.Name\"][pair[0]],dataC[\"First.Name\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA[\"Last.Name\"][pair[0]],dataC[\"Last.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA[\"Middle.Name\"][pair[0]],dataC[\"Middle.Name\"][pair[1]]))\n",
    "    row.append(0) # no credentials in dataC\n",
    "    row.append(safe_jw(dataA[\"City\"][pair[0]],dataC[\"City\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA[\"State\"][pair[0]],dataC[\"State\"][pair[1]]))\n",
    "    row.append(0) # no country in dataC\n",
    "    row.append(safe_jw(dataA[\"ZIP\"][pair[0]],dataC[\"ZIP\"][pair[1]]))\n",
    "    row.append(0) # no address in dataC \n",
    "    row.append(matching_words(dataA['Type'][pair[0]],dataC['Type'][pair[1]]))\n",
    "\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "columns = [\n",
    "    \"pair\",\n",
    "    \"NPI_match\",\n",
    "    \"First.Name\",\n",
    "    \"Last.Name\",\n",
    "    \"Middle.Name\",\n",
    "    \"Credentials\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"ZIP\",\n",
    "    \"Street.Address\",\n",
    "    \"Type\"\n",
    "]\n",
    "\n",
    "df_AC = pd.DataFrame(rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cfa610",
   "metadata": {},
   "source": [
    "Let's do the same thing for data sets B and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b9d76890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPI_check_BC(i,j):\n",
    "    if dataB[\"NPI\"][i]==dataC[\"NPI\"][j]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "34960a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498706"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_candidate_pairs_BC = set(\n",
    "    SN_blocking(dataB_prov, dataC_prov, window_size=5)\n",
    ")\n",
    "\n",
    "len(SNB_candidate_pairs_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c0609512",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pair in SNB_candidate_pairs_BC:\n",
    "    row = []\n",
    "\n",
    "    row.append(pair)\n",
    "    row.append(NPI_check_BC(pair[0],pair[1]))\n",
    "    row.append(safe_jw(dataB[\"First.Name\"][pair[0]],dataC[\"First.Name\"][pair[1]]))\n",
    "    row.append(safe_jw(dataB[\"Last.Name\"][pair[0]],dataC[\"Last.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataB[\"Middle.Name\"][pair[0]],dataC[\"Middle.Name\"][pair[1]]))\n",
    "    row.append(0) # no credentials in dataC\n",
    "    row.append(safe_jw(dataB[\"City\"][pair[0]],dataC[\"City\"][pair[1]]))\n",
    "    row.append(safe_lev(dataB[\"State\"][pair[0]],dataC[\"State\"][pair[1]]))\n",
    "    row.append(0) # no country in dataC\n",
    "    row.append(safe_jw(dataB[\"ZIP\"][pair[0]],dataC[\"ZIP\"][pair[1]]))\n",
    "    row.append(0) # no address in dataC \n",
    "    row.append(matching_words(dataB['Type'][pair[0]],dataC['Type'][pair[1]]))\n",
    "\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "columns = [\n",
    "    \"pair\",\n",
    "    \"NPI_match\",\n",
    "    \"First.Name\",\n",
    "    \"Last.Name\",\n",
    "    \"Middle.Name\",\n",
    "    \"Credentials\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"ZIP\",\n",
    "    \"Street.Address\",\n",
    "    \"Type\"\n",
    "]\n",
    "\n",
    "df_BC = pd.DataFrame(rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432f15e",
   "metadata": {},
   "source": [
    "Now we will put these three similarity table on top of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c3ddc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df,df_AC,df_BC],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01199be2",
   "metadata": {},
   "source": [
    "And now we will train our model on this new data using the hyper parameters we found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "dd764295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.05, n_estimators=300,\n",
       "                           random_state=42, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.05, n_estimators=300,\n",
       "                           random_state=42, subsample=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, n_estimators=300,\n",
       "                           random_state=42, subsample=0.8)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = df_new.drop(columns=[\"pair\", \"NPI_match\"])\n",
    "y_all = df_new[\"NPI_match\"]\n",
    "\n",
    "final_model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X_all, y_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6c65a",
   "metadata": {},
   "source": [
    "We will now try to interpret our model by checking the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "44d81c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First.Name</td>\n",
       "      <td>0.657323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>State</td>\n",
       "      <td>0.193077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Type</td>\n",
       "      <td>0.060079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last.Name</td>\n",
       "      <td>0.052447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City</td>\n",
       "      <td>0.014711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Street.Address</td>\n",
       "      <td>0.013428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Middle.Name</td>\n",
       "      <td>0.008327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credentials</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "0      First.Name    0.657323\n",
       "5           State    0.193077\n",
       "9            Type    0.060079\n",
       "1       Last.Name    0.052447\n",
       "4            City    0.014711\n",
       "8  Street.Address    0.013428\n",
       "2     Middle.Name    0.008327\n",
       "6         Country    0.000327\n",
       "7             ZIP    0.000150\n",
       "3     Credentials    0.000131"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": X_all.columns,\n",
    "    \"importance\": final_model.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d9051",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b93056",
   "metadata": {},
   "source": [
    "Now we will test our model on the test data. However, we again need to first create the three similarity tables. Then we will stack them on top of each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e29bdf",
   "metadata": {},
   "source": [
    "Let's first create the similarity table for test data set A and B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ace58a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPI_check_test(i,j):\n",
    "    if dataA_test[\"NPI\"][i]==dataB_test[\"NPI\"][j]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1db6ce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068108"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_test_pairs = set(\n",
    "    SN_blocking(dataA_test, dataB_test, window_size=5)\n",
    ")\n",
    "\n",
    "len(SNB_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a0500dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for pair in SNB_test_pairs:\n",
    "    row = []\n",
    "\n",
    "    row.append(pair)\n",
    "    row.append(NPI_check_test(pair[0],pair[1]))\n",
    "    row.append(safe_jw(dataA_test[\"First.Name\"][pair[0]],dataB_test[\"First.Name\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA_test[\"Last.Name\"][pair[0]],dataB_test[\"Last.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA_test[\"Middle.Name\"][pair[0]],dataB_test[\"Middle.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA_test[\"Credentials\"][pair[0]],dataB_test[\"Credentials\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA_test[\"City\"][pair[0]],dataB_test[\"City\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA_test[\"State\"][pair[0]],dataB_test[\"State\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA_test[\"Country\"][pair[0]],dataB_test[\"Country\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA_test[\"ZIP\"][pair[0]],dataB_test[\"ZIP\"][pair[1]]))\n",
    "    row.append(compare_two_addresses(dataA_test['Street.Address'][pair[0]],dataB_test['Street.Address'][pair[1]],canonical_map))\n",
    "    row.append(matching_words(dataA_test['Type'][pair[0]],dataB_test['Type'][pair[1]]))\n",
    "\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "columns = [\n",
    "    \"pair\",\n",
    "    \"NPI_match\",\n",
    "    \"First.Name\",\n",
    "    \"Last.Name\",\n",
    "    \"Middle.Name\",\n",
    "    \"Credentials\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"ZIP\",\n",
    "    \"Street.Address\",\n",
    "    \"Type\"\n",
    "]\n",
    "\n",
    "test_data = pd.DataFrame(rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45fab0",
   "metadata": {},
   "source": [
    "Let's do the same thing for test data A and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "11669744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPI_check_test_AC(i,j):\n",
    "    if dataA_test[\"NPI\"][i]==dataC_test[\"NPI\"][j]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4d66dadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962514"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_test_pairs_AC = set(\n",
    "    SN_blocking(dataA_test, dataC_test, window_size=5)\n",
    ")\n",
    "\n",
    "len(SNB_test_pairs_AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "3c45632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pair in SNB_test_pairs_AC:\n",
    "    row = []\n",
    "\n",
    "    row.append(pair)\n",
    "    row.append(NPI_check_test_AC(pair[0],pair[1]))\n",
    "    row.append(safe_jw(dataA_test[\"First.Name\"][pair[0]],dataC_test[\"First.Name\"][pair[1]]))\n",
    "    row.append(safe_jw(dataA_test[\"Last.Name\"][pair[0]],dataC_test[\"Last.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA_test[\"Middle.Name\"][pair[0]],dataC_test[\"Middle.Name\"][pair[1]]))\n",
    "    row.append(0) # no credentials in dataC\n",
    "    row.append(safe_jw(dataA_test[\"City\"][pair[0]],dataC_test[\"City\"][pair[1]]))\n",
    "    row.append(safe_lev(dataA_test[\"State\"][pair[0]],dataC_test[\"State\"][pair[1]]))\n",
    "    row.append(0) # no country in dataC\n",
    "    row.append(safe_jw(dataA_test[\"ZIP\"][pair[0]],dataC_test[\"ZIP\"][pair[1]]))\n",
    "    row.append(0) # no country in dataC\n",
    "    row.append(matching_words(dataA_test['Type'][pair[0]],dataC_test['Type'][pair[1]]))\n",
    "\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "columns = [\n",
    "    \"pair\",\n",
    "    \"NPI_match\",\n",
    "    \"First.Name\",\n",
    "    \"Last.Name\",\n",
    "    \"Middle.Name\",\n",
    "    \"Credentials\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"ZIP\",\n",
    "    \"Street.Address\",\n",
    "    \"Type\"\n",
    "]\n",
    "\n",
    "test_data_AC = pd.DataFrame(rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b12b3",
   "metadata": {},
   "source": [
    "Finally, let's do the same thing for test data B and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "8bee84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NPI_check_test_BC(i,j):\n",
    "    if dataB_test[\"NPI\"][i]==dataC_test[\"NPI\"][j]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4d7e5360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940604"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNB_test_pairs_BC = set(\n",
    "    SN_blocking(dataB_test, dataC_test, window_size=5)\n",
    ")\n",
    "\n",
    "len(SNB_test_pairs_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "bef0803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pair in SNB_test_pairs_BC:\n",
    "    row = []\n",
    "\n",
    "    row.append(pair)\n",
    "    row.append(NPI_check_test_BC(pair[0],pair[1]))\n",
    "    row.append(safe_jw(dataB_test[\"First.Name\"][pair[0]],dataC_test[\"First.Name\"][pair[1]]))\n",
    "    row.append(safe_jw(dataB_test[\"Last.Name\"][pair[0]],dataC_test[\"Last.Name\"][pair[1]]))\n",
    "    row.append(safe_lev(dataB_test[\"Middle.Name\"][pair[0]],dataC_test[\"Middle.Name\"][pair[1]]))\n",
    "    row.append(0) # no credentials in dataC\n",
    "    row.append(safe_jw(dataB_test[\"City\"][pair[0]],dataC_test[\"City\"][pair[1]]))\n",
    "    row.append(safe_lev(dataB_test[\"State\"][pair[0]],dataC_test[\"State\"][pair[1]]))\n",
    "    row.append(0) # no country in dataC\n",
    "    row.append(safe_jw(dataB_test[\"ZIP\"][pair[0]],dataC_test[\"ZIP\"][pair[1]]))\n",
    "    row.append(0) # no country in dataC\n",
    "    row.append(matching_words(dataB_test['Type'][pair[0]],dataC_test['Type'][pair[1]]))\n",
    "\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "columns = [\n",
    "    \"pair\",\n",
    "    \"NPI_match\",\n",
    "    \"First.Name\",\n",
    "    \"Last.Name\",\n",
    "    \"Middle.Name\",\n",
    "    \"Credentials\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"ZIP\",\n",
    "    \"Street.Address\",\n",
    "    \"Type\"\n",
    "]\n",
    "\n",
    "test_data_BC = pd.DataFrame(rows, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251ff4a",
   "metadata": {},
   "source": [
    "Now we will stack them on top of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "5b970170",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test_data,test_data_AC,test_data_BC],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "178bc474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=[\"pair\", \"NPI_match\"])\n",
    "y_test = test[\"NPI_match\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "4e81bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.9635\n",
      "Test Recall:    0.9466\n",
      "Test F1:        0.9550\n",
      "Test ROC AUC:   0.9996\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = final_model.predict(X_test)\n",
    "y_test_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall:    {test_recall:.4f}\")\n",
    "print(f\"Test F1:        {test_f1:.4f}\")\n",
    "print(f\"Test ROC AUC:   {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e00d29",
   "metadata": {},
   "source": [
    "We will apply bootstrping here to check how much my test results changed if my test data changed slightly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ec579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision CI: [0.96249332 0.96449145]\n",
      "Recall CI:    [0.94539686 0.94784002]\n",
      "F1 CI:        [0.9542114  0.95586109]\n",
      "ROC AUC CI:   [0.99958322 0.99961113]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Predictions\n",
    "y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "# Convert to NumPy \n",
    "y_true = y_test.to_numpy()\n",
    "y_pred = y_pred.astype(np.int8)\n",
    "y_prob = y_prob.astype(np.float32)\n",
    "\n",
    "n = y_true.shape[0]\n",
    "n_bootstraps = 500  \n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Preallocate arrays\n",
    "precisions = np.empty(n_bootstraps)\n",
    "recalls = np.empty(n_bootstraps)\n",
    "f1s = np.empty(n_bootstraps)\n",
    "aucs = np.empty(n_bootstraps)\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    idx = rng.integers(0, n, size=n)\n",
    "\n",
    "    y_true_bs = y_true[idx]\n",
    "    y_pred_bs = y_pred[idx]\n",
    "    y_prob_bs = y_prob[idx]\n",
    "\n",
    "    precisions[i] = precision_score(y_true_bs, y_pred_bs, zero_division=0)\n",
    "    recalls[i] = recall_score(y_true_bs, y_pred_bs)\n",
    "    f1s[i] = f1_score(y_true_bs, y_pred_bs)\n",
    "    aucs[i] = roc_auc_score(y_true_bs, y_prob_bs)\n",
    "\n",
    "# Confidence interval function\n",
    "def ci(x):\n",
    "    return np.percentile(x, [2.5, 97.5])\n",
    "\n",
    "print(\"Precision CI:\", ci(precisions))\n",
    "print(\"Recall CI:   \", ci(recalls))\n",
    "print(\"F1 CI:       \", ci(f1s))\n",
    "print(\"ROC AUC CI:  \", ci(aucs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9800de",
   "metadata": {},
   "source": [
    "Realize that all of the original results lie in between the given confidence intervals. That means our model did a great job learning the behaviour of the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
